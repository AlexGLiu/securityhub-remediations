{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview In this workshop you will learn how to implement automated remediations of findings submitted to AWS Security Hub leveraging an open source tool named Cloud Custodian , with no prior knowledge of either is required. However, this workshop is not intended to to provide a complete introduction to writing polices for Cloud Custodian, for that please refer to the Getting Started documentation or alternatively the introductory presentation on Cloud Custodian The automated remediations in this workshop are implemented as AWS Lambda Functions which get invoked by Cloudwatch Events . The CloudWatch Events are generated by AWS Security Hub as a result of a Console user invoking a Custom Action , or when a finding is imported into Security Hub . Your feedback is highly desired, please submit a new issue if you run into any problems, even if you figure it out yourself, please report the problem so we can attempt to make this workshop as error proof as possible. Level : Intermediate Duration : 1 - 2 hours CSF Functions: Detect, Respond CAF Components: Detective, Responsive Prerequisites: AWS Account with an Admin IAM user/role with AWS CLI configured. If you are doing this Workshop as part of an AWS Event where Event Engine is being used, these will be supplied. Scenario You are a Security Engineer who has just been tasked with automating some of the common steps that Security Analysts take when responding to insecure configuration, discovered vulnerabilities, or actual attacks. Architecture For this Workshop you will view source files using Cloud 9 and invoke command lines via it's terminal window connected to an EC2 instance. The automated remediations in this workshop will be deployed by using that terminal window to invoke Cloud Custodian running within a docker container. Each module includes the execution of a Cloud Custodian policy, which is file written in a simple YAML based DSL which defines rules. Most of the policies result in Cloud Custodian dynamically generating and deploying a Lambda Function, then deploying a CloudWatch Event rule with an event filter and a trigger to invoke the same Lambda function it just deployed. The cloudformation in this workshop sets up the following: 1. AWS Cloud 9 Environment with associated ec2 instance. 2. IAM policies, Role, and Instance-Profiles. 3. An ec2 instance to be used as a test target. 4. IAM user to demo ability to disable it's access keys. As part of the Workshop, Security Hub and Guard Duty will be enabled. Presentation deck Workshop Presentation Deck Modules This workshop is broken up into the following modules below: Environment Build and Configuration GuardDuty DNS Event on EC2 Instance Security Hub Custom Actions Vulnerability Event on EC2 Instance with Very Risky Configuration GuardDuty Event on IAMUser Remediate an Public EBS-Snapshot Cleanup of Resources -- not needed using an AWS Event provided account","title":"Overview"},{"location":"#overview","text":"In this workshop you will learn how to implement automated remediations of findings submitted to AWS Security Hub leveraging an open source tool named Cloud Custodian , with no prior knowledge of either is required. However, this workshop is not intended to to provide a complete introduction to writing polices for Cloud Custodian, for that please refer to the Getting Started documentation or alternatively the introductory presentation on Cloud Custodian The automated remediations in this workshop are implemented as AWS Lambda Functions which get invoked by Cloudwatch Events . The CloudWatch Events are generated by AWS Security Hub as a result of a Console user invoking a Custom Action , or when a finding is imported into Security Hub . Your feedback is highly desired, please submit a new issue if you run into any problems, even if you figure it out yourself, please report the problem so we can attempt to make this workshop as error proof as possible. Level : Intermediate Duration : 1 - 2 hours CSF Functions: Detect, Respond CAF Components: Detective, Responsive Prerequisites: AWS Account with an Admin IAM user/role with AWS CLI configured. If you are doing this Workshop as part of an AWS Event where Event Engine is being used, these will be supplied.","title":"Overview"},{"location":"#scenario","text":"You are a Security Engineer who has just been tasked with automating some of the common steps that Security Analysts take when responding to insecure configuration, discovered vulnerabilities, or actual attacks.","title":"Scenario"},{"location":"#architecture","text":"For this Workshop you will view source files using Cloud 9 and invoke command lines via it's terminal window connected to an EC2 instance. The automated remediations in this workshop will be deployed by using that terminal window to invoke Cloud Custodian running within a docker container. Each module includes the execution of a Cloud Custodian policy, which is file written in a simple YAML based DSL which defines rules. Most of the policies result in Cloud Custodian dynamically generating and deploying a Lambda Function, then deploying a CloudWatch Event rule with an event filter and a trigger to invoke the same Lambda function it just deployed. The cloudformation in this workshop sets up the following: 1. AWS Cloud 9 Environment with associated ec2 instance. 2. IAM policies, Role, and Instance-Profiles. 3. An ec2 instance to be used as a test target. 4. IAM user to demo ability to disable it's access keys. As part of the Workshop, Security Hub and Guard Duty will be enabled.","title":"Architecture"},{"location":"#presentation-deck","text":"Workshop Presentation Deck","title":"Presentation deck"},{"location":"#modules","text":"This workshop is broken up into the following modules below: Environment Build and Configuration GuardDuty DNS Event on EC2 Instance Security Hub Custom Actions Vulnerability Event on EC2 Instance with Very Risky Configuration GuardDuty Event on IAMUser Remediate an Public EBS-Snapshot Cleanup of Resources -- not needed using an AWS Event provided account","title":"Modules"},{"location":"01-environment-setup/","text":"Module 1: Environment build and configuration To Get started with this workshop as part of the an AWS Event where Event Engine is being used, please follow the steps directly following, otherwise skip down to the section labeled \"Getting Started using your own account\" . Getting Started at AWS event where the Event Engine is being used Open https://dashboard.eventengine.run/login in a new Tab or Window to access the Event Engine Dashboard Enter the team hash code that you were provided and click Proceed. Look for a section of the page labeled \"Event Engine Team Role\" then click \"Open Console\" button within the Login Link section Make sure you are in the correct region. Skip the \"Getting started using your own account\" and continue with the \"Manual Setup Steps\" Getting Started using your own account: In order to complete this workshop, you'll need a valid, usable AWS Account. Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for unless you have explicit approval to conduct security related training exercises in it. We strongly recommend that you use a non-production AWS account for this workshop such as a training, sandbox or personal account. Attempts by multiple participants to use the same account for this workshop will fail, due to the deployment of Named IAM Roles and Users. You will incur charges for the AWS resources used in this workshop. The charges for some of the resources may be covered through the AWS Free Tier . The demo uses free tier choices wherever possible. You must run this workshop in a region support by AWS Cloud9 If you choose to use an existing VPC, it needs to have connectivity thru an IGW to reach AWS public endpoints as some of the services used do not yet support VPC Endpoints. Now we need to download a copy of the CloudFormation template for this Workshop. If you don't have the program wget, use any other method you are comfortable with, such as curl or a browser. wget https://github.com/FireballDWF/securityhub-remediations/blob/master/module1/securityhub-remediations-workshop.yml Next we start to to create the cloudformation stack for the workshop, starting by opening the AWS Console, navigate to Cloudformation, click on the \"Create stack\" button, select the \"With new resources (standard)\" option, then in the \"Specify template\" section, click \"Upload a template file\", then click \"Choose file\", and when the File Dialog window pops up, select the file downloaded in the prior step. Click Next. Enter in a Stack name, for example \"SecurityHubRemediations\". Change the value of \"EventEngine\" to False. Change the value of VpcId to \"CreateNew\", unless you have a good reason to want to use an existing VPC and if so, enter the VpcId instead Click the \"Next\" button. On the \"Configure stack options\" page, Click the \"Next\" button. On the \"Review\" page, click the checkbox to the left of \"I acknowledge that AWS Cloudformation might create IAM resources with custom names\", as it will. Click \"Create Stack\" Wait until the stack if finished creating before starting the next step as the Cloud9 environment needs to be enabled before it will work correctly Manual Setup Steps 1. 2. Open the Cloud9 IDE which provides the ability to review files and execute commands in a browser based terminal window. Starting from the main AWS Management Console, within the \"Find Services\" textbox, type \"Cloud9\" then hit Enter. 2. Now click the \"Open IDE\" button. 3. In the bottom part of the browser tab which opens up, look for a tab with a label starting with \"bash\", where the window contents contain \"~/environment $\". This is the browser based terminal session you'll use for the rest of the workshop for any command line steps. Run the following command to enable SecurityHub in the account, unless you are using your own account and know that it's already enabled. If you have full unresticted Admin Access, and get an error, then the most likely reason is that it is already enabled. aws securityhub enable-security-hub You need to have GuardDuty enabled on the account for module 2 and 5 to work, if not yet then either run the following command or follow the steps to enable on the console aws guardduty create-detector --enable The next step is to get a copy of the files required for this workshop by cloning the workshop's github repo specifing the eventengine branch. git clone --single-branch --branch master https://github.com/FireballDWF/securityhub-remediations.git && cd securityhub-remediations Next step is to pull down the latest version of the Cloud Custodian docker container image and setup the repeative part of the command line export SECHUBWORKSHOP_CONTAINER=cloudcustodian/c7n export CLOUDCUSTODIANDOCKERCMD=\"docker run -it --rm --cap-drop ALL -v /home/ec2-user/environment/securityhub-remediations:/home/custodian/securityhub-remediations:ro -v /home/ec2-user/.aws:/home/custodian/.aws:ro ${ SECHUBWORKSHOP_CONTAINER } run --cache-period 0 -s /tmp -c\" docker pull ${ SECHUBWORKSHOP_CONTAINER } TOKEN=$(curl --silent -X PUT \"http://169.254.169.254/latest/api/token\" -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\") export AWS_DEFAULT_REGION=$(curl --silent -H \"X-aws-ec2-metadata-token: $TOKEN \" http://169.254.169.254/latest/meta-data/placement/availability-zone | sed 's/\\(.*\\)[a-z]/\\1/') This step tests the environment by invoking a Cloud Custodian Policy which reports that an ec2 instance has a vulnerability. ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module1/force-vulnerability-finding.yml You should expect to see 2 output lines, one containing \"count:1\" and another containing \"resources:1\", similar to the following output. If you get an error on \"batch-import-findings\" then it means SecurityHub has not been enabled. Example output is from us-east-1, however your results should indicate the region being used for the workshop event. 2019-08-11 16:33:57,326: custodian.policy:INFO policy:ec2-force-vulnerabilities resource:ec2 region:us-east-1 count:1 time:0.00 2019-08-11 16:33:57,787: custodian.policy:INFO policy:ec2-force-vulnerabilities action:instancefinding resources:1 execution_time:0.46 Here is a breakdown of the command you just ran: Command Line Component Explaination docker run Run a docker container -it interactive/foreground mode --rm clean up docker container when container exits --cap-drop ALL Drop all Linux kernel capabilities as recommended in Rule #3 of the Docker Security Cheat Sheet -v /home/ec2-user/environment/securityhub-remediations:/home/custodian/securityhub-remediations:ro map the files for the workshop into the container so the cloud custodian policies are available insider the container. volume is mapped in ReadOnly mode -v /home/ec2-user/.aws:/home/custodian/.aws:ro maps the aws cli configuration files into the container in read-only mode. Cloud Custodian uses the same configuration files, as both use the boto3 Python SDK ${SECHUBWORKSHOP_CONTAINER} evaluates to cloudcustodian/c7n which is the docker container image which is downloaded from https://hub.docker.com/r/cloudcustodian/c7n run instructs Cloud Custodian to run a policy. This is the first part of the command line which is passed to CloudCustodian --cache-period 0 disables cloud custodian's caching of api call results -s /tmp specifies the directory where log and resource data is placed -c securityhub-remediations/module1/force-vulnerability-finding.yml specifies the actual policy to run If you received the expected output lines, congratulations, you have successfully tested the environment setup by having Cloud Custodian submit a finding to Security Hub. Proceed to the next module. After you have successfully setup your environment, you can proceed to the next module.","title":"Module 1: Environment Build"},{"location":"01-environment-setup/#module-1-environment-build-and-configuration","text":"To Get started with this workshop as part of the an AWS Event where Event Engine is being used, please follow the steps directly following, otherwise skip down to the section labeled \"Getting Started using your own account\" .","title":"Module 1: Environment build and configuration"},{"location":"01-environment-setup/#getting-started-at-aws-event-where-the-event-engine-is-being-used","text":"Open https://dashboard.eventengine.run/login in a new Tab or Window to access the Event Engine Dashboard Enter the team hash code that you were provided and click Proceed. Look for a section of the page labeled \"Event Engine Team Role\" then click \"Open Console\" button within the Login Link section Make sure you are in the correct region. Skip the \"Getting started using your own account\" and continue with the \"Manual Setup Steps\"","title":"Getting Started at AWS event where the Event Engine is being used"},{"location":"01-environment-setup/#getting-started-using-your-own-account","text":"In order to complete this workshop, you'll need a valid, usable AWS Account. Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for unless you have explicit approval to conduct security related training exercises in it. We strongly recommend that you use a non-production AWS account for this workshop such as a training, sandbox or personal account. Attempts by multiple participants to use the same account for this workshop will fail, due to the deployment of Named IAM Roles and Users. You will incur charges for the AWS resources used in this workshop. The charges for some of the resources may be covered through the AWS Free Tier . The demo uses free tier choices wherever possible. You must run this workshop in a region support by AWS Cloud9 If you choose to use an existing VPC, it needs to have connectivity thru an IGW to reach AWS public endpoints as some of the services used do not yet support VPC Endpoints. Now we need to download a copy of the CloudFormation template for this Workshop. If you don't have the program wget, use any other method you are comfortable with, such as curl or a browser. wget https://github.com/FireballDWF/securityhub-remediations/blob/master/module1/securityhub-remediations-workshop.yml Next we start to to create the cloudformation stack for the workshop, starting by opening the AWS Console, navigate to Cloudformation, click on the \"Create stack\" button, select the \"With new resources (standard)\" option, then in the \"Specify template\" section, click \"Upload a template file\", then click \"Choose file\", and when the File Dialog window pops up, select the file downloaded in the prior step. Click Next. Enter in a Stack name, for example \"SecurityHubRemediations\". Change the value of \"EventEngine\" to False. Change the value of VpcId to \"CreateNew\", unless you have a good reason to want to use an existing VPC and if so, enter the VpcId instead Click the \"Next\" button. On the \"Configure stack options\" page, Click the \"Next\" button. On the \"Review\" page, click the checkbox to the left of \"I acknowledge that AWS Cloudformation might create IAM resources with custom names\", as it will. Click \"Create Stack\" Wait until the stack if finished creating before starting the next step as the Cloud9 environment needs to be enabled before it will work correctly","title":"Getting Started using your own account:"},{"location":"01-environment-setup/#manual-setup-steps","text":"1. 2. Open the Cloud9 IDE which provides the ability to review files and execute commands in a browser based terminal window. Starting from the main AWS Management Console, within the \"Find Services\" textbox, type \"Cloud9\" then hit Enter. 2. Now click the \"Open IDE\" button. 3. In the bottom part of the browser tab which opens up, look for a tab with a label starting with \"bash\", where the window contents contain \"~/environment $\". This is the browser based terminal session you'll use for the rest of the workshop for any command line steps. Run the following command to enable SecurityHub in the account, unless you are using your own account and know that it's already enabled. If you have full unresticted Admin Access, and get an error, then the most likely reason is that it is already enabled. aws securityhub enable-security-hub You need to have GuardDuty enabled on the account for module 2 and 5 to work, if not yet then either run the following command or follow the steps to enable on the console aws guardduty create-detector --enable The next step is to get a copy of the files required for this workshop by cloning the workshop's github repo specifing the eventengine branch. git clone --single-branch --branch master https://github.com/FireballDWF/securityhub-remediations.git && cd securityhub-remediations Next step is to pull down the latest version of the Cloud Custodian docker container image and setup the repeative part of the command line export SECHUBWORKSHOP_CONTAINER=cloudcustodian/c7n export CLOUDCUSTODIANDOCKERCMD=\"docker run -it --rm --cap-drop ALL -v /home/ec2-user/environment/securityhub-remediations:/home/custodian/securityhub-remediations:ro -v /home/ec2-user/.aws:/home/custodian/.aws:ro ${ SECHUBWORKSHOP_CONTAINER } run --cache-period 0 -s /tmp -c\" docker pull ${ SECHUBWORKSHOP_CONTAINER } TOKEN=$(curl --silent -X PUT \"http://169.254.169.254/latest/api/token\" -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\") export AWS_DEFAULT_REGION=$(curl --silent -H \"X-aws-ec2-metadata-token: $TOKEN \" http://169.254.169.254/latest/meta-data/placement/availability-zone | sed 's/\\(.*\\)[a-z]/\\1/') This step tests the environment by invoking a Cloud Custodian Policy which reports that an ec2 instance has a vulnerability. ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module1/force-vulnerability-finding.yml You should expect to see 2 output lines, one containing \"count:1\" and another containing \"resources:1\", similar to the following output. If you get an error on \"batch-import-findings\" then it means SecurityHub has not been enabled. Example output is from us-east-1, however your results should indicate the region being used for the workshop event. 2019-08-11 16:33:57,326: custodian.policy:INFO policy:ec2-force-vulnerabilities resource:ec2 region:us-east-1 count:1 time:0.00 2019-08-11 16:33:57,787: custodian.policy:INFO policy:ec2-force-vulnerabilities action:instancefinding resources:1 execution_time:0.46 Here is a breakdown of the command you just ran: Command Line Component Explaination docker run Run a docker container -it interactive/foreground mode --rm clean up docker container when container exits --cap-drop ALL Drop all Linux kernel capabilities as recommended in Rule #3 of the Docker Security Cheat Sheet -v /home/ec2-user/environment/securityhub-remediations:/home/custodian/securityhub-remediations:ro map the files for the workshop into the container so the cloud custodian policies are available insider the container. volume is mapped in ReadOnly mode -v /home/ec2-user/.aws:/home/custodian/.aws:ro maps the aws cli configuration files into the container in read-only mode. Cloud Custodian uses the same configuration files, as both use the boto3 Python SDK ${SECHUBWORKSHOP_CONTAINER} evaluates to cloudcustodian/c7n which is the docker container image which is downloaded from https://hub.docker.com/r/cloudcustodian/c7n run instructs Cloud Custodian to run a policy. This is the first part of the command line which is passed to CloudCustodian --cache-period 0 disables cloud custodian's caching of api call results -s /tmp specifies the directory where log and resource data is placed -c securityhub-remediations/module1/force-vulnerability-finding.yml specifies the actual policy to run If you received the expected output lines, congratulations, you have successfully tested the environment setup by having Cloud Custodian submit a finding to Security Hub. Proceed to the next module. After you have successfully setup your environment, you can proceed to the next module.","title":"Manual Setup Steps"},{"location":"02-guardduty-dns-event/","text":"Module 2 - Automated Remediations - GuardDuty DNS Event on EC2 Instance Run the following command which runs a policy named ec2-sechub-remediate-severity-with-findings which instructs Cloud Custodian to dynamically generate and deploy a lambda, which will be invoked when SecurityHub generates a Cloudwatch Event when sent a finding. In this module, the finding will be triggered when GuardDuty generates a finding, and the severity of the is greater than or equal to 31, and the EC2 instance has any vulnerability previously reported to SecurityHub ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module2/ec2-sechub-remediate-severity-with-findings.yml Next run the following command which leverages Systems Manager's Run Command to run an \"nslookup\" command on the ec2 instance tag:Name RemediationTestTarget where it's looking up a dns name which GuardDuty will detect as Command and Control activity aws ssm send-command --document-name AWS-RunShellScript --parameters commands=[\"nslookup guarddutyc2activityb.com\"] --targets \"Key=tag:Name,Values=RemediationTestTarget\" --comment \"Force GuardDutyFinding\" --cloud-watch-output-config CloudWatchLogGroupName=/workshop/SecurityHubRemediationsWorkshop,CloudWatchOutputEnabled=true As it can take a long time (more than 20 minutes often around 2 hours) for GuardDuty to generate a DNS based finding, please proceed to the next module, then come back to the next review step later. Review Cloudwatch LogGroup \"/aws/lambda/custodian-ec2-sechub-remediate-severity-with-findings\" to see that it did a Snapshot.","title":"Module 2: GuardDuty DNS Event on EC2 Instance"},{"location":"02-guardduty-dns-event/#module-2-automated-remediations-guardduty-dns-event-on-ec2-instance","text":"Run the following command which runs a policy named ec2-sechub-remediate-severity-with-findings which instructs Cloud Custodian to dynamically generate and deploy a lambda, which will be invoked when SecurityHub generates a Cloudwatch Event when sent a finding. In this module, the finding will be triggered when GuardDuty generates a finding, and the severity of the is greater than or equal to 31, and the EC2 instance has any vulnerability previously reported to SecurityHub ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module2/ec2-sechub-remediate-severity-with-findings.yml Next run the following command which leverages Systems Manager's Run Command to run an \"nslookup\" command on the ec2 instance tag:Name RemediationTestTarget where it's looking up a dns name which GuardDuty will detect as Command and Control activity aws ssm send-command --document-name AWS-RunShellScript --parameters commands=[\"nslookup guarddutyc2activityb.com\"] --targets \"Key=tag:Name,Values=RemediationTestTarget\" --comment \"Force GuardDutyFinding\" --cloud-watch-output-config CloudWatchLogGroupName=/workshop/SecurityHubRemediationsWorkshop,CloudWatchOutputEnabled=true As it can take a long time (more than 20 minutes often around 2 hours) for GuardDuty to generate a DNS based finding, please proceed to the next module, then come back to the next review step later. Review Cloudwatch LogGroup \"/aws/lambda/custodian-ec2-sechub-remediate-severity-with-findings\" to see that it did a Snapshot.","title":"Module 2 - Automated Remediations - GuardDuty DNS Event on EC2 Instance"},{"location":"03-securityhub-custom-actions/","text":"Module 3 - Security Hub Custom Actions - Human initiated automation Custom Actions in Security Hub are useful for analysts working with the Security Hub console who want to send a specific finding, or a small set of findings, to a response or remediation workflow. The finding generated by the test in the first module will be used within this module to explore Custom Actions. Run the following: ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module3/ec2-sechub-custom-actions.yml You should see lines of output line like the following: 2019-09-01 19:20:29,021: custodian.policy:INFO Provisioning policy lambda DenySnapStop 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda DisableKey 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda Delete 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda PostOpsItem 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda RemPA 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-DenySnapStop 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-DisableKey 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-Delete 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-PostOpsItem 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-RemPA Note that the string after 'Provisioning policy lambda\" matches the policy names contained within the ec2-sechub-custom-actions.yml file from the last docker command. The names of the generated lambdas will be composed of that policy names prefixed with \"custodian-\". Cloudwatch logs are generated following standard naming convention, /aws/lamabda/custodian-$(PolicyName) Within the Management Console, navigate to the Security Hub service. In the left hand navigation area, click on Findings. You should see a row where the value of the Title column is \"ec2-force-vulnerabilities\", if not then in the Findings search box, type Title, under the pop-up Filters click on Title, then in the new popup, enter \"ec2-force-vulnerabilities\" then click Apply. Click the checkbox (left hand side) for the finding. In the upper right, click \"Actions\" then in the popup click on \"Ec2 DenySnapStop\" You should observe a green notification at top of page saying \"Successfully send findings to Amazon CloudwatchEvents\". I've submitted a request to include the action name in that message. Review the Cloudwatch log of the Lambda which got invoked. Log Group names are composed of the prefix \"/aws/lambda/custodian-\" followed by the policy name, so in this case \"aws/lambda/custodian-DenySnapStop\". Within that log group, open the most recent Log stream. Lines with \"ERROR\" indicate something is wrong, please let the event facilitor know if you see an ERROR. You should see at least a line containing \"invoking action:\" for each action in the policy. Optional: Review the complete payload of the Cloudwatch event which is logged directly after a line (usually line #2) ending with the text \"Processing event\". Optional, you can use the AWS Console and/or cli to confirm that the instance named \"RemediationTestTarget\" has really be stopped, snapshotted, and the IAM Instance Profile dissassociated. Now run the following command to reassociate the InstanceProfile as it's needed for the next module. aws ec2 associate - iam - instance - profile --iam-instance-profile Name=SecurityHubRemediationWorkshopCli --instance-id $(aws ec2 describe-instances --filters Name=tag:Name,Values=RemediationTestTarget --query Reservations[*].Instances[*].[InstanceId] --output text) Now run the following command to start the instance so the instance is ready for the next module. aws ec2 start - instances --instance-ids $(aws ec2 describe-instances --filters Name=tag:Name,Values=RemediationTestTarget Name=instance-state-name,Values=stopped --query Reservations[*].Instances[*].[InstanceId] --output text) If you get an error, the most likely reason is that the instance is still in the stopping state, wait 5-10 seconds then retry","title":"Module 3: Security Hub Custom Actions"},{"location":"03-securityhub-custom-actions/#module-3-security-hub-custom-actions-human-initiated-automation","text":"Custom Actions in Security Hub are useful for analysts working with the Security Hub console who want to send a specific finding, or a small set of findings, to a response or remediation workflow. The finding generated by the test in the first module will be used within this module to explore Custom Actions. Run the following: ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module3/ec2-sechub-custom-actions.yml You should see lines of output line like the following: 2019-09-01 19:20:29,021: custodian.policy:INFO Provisioning policy lambda DenySnapStop 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda DisableKey 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda Delete 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda PostOpsItem 2019-09-01 19:20:30,885: custodian.policy:INFO Provisioning policy lambda RemPA 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-DenySnapStop 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-DisableKey 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-Delete 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-PostOpsItem 2019-09-01 19:20:32,222: custodian.serverless:INFO Publishing custodian policy lambda function custodian-RemPA Note that the string after 'Provisioning policy lambda\" matches the policy names contained within the ec2-sechub-custom-actions.yml file from the last docker command. The names of the generated lambdas will be composed of that policy names prefixed with \"custodian-\". Cloudwatch logs are generated following standard naming convention, /aws/lamabda/custodian-$(PolicyName) Within the Management Console, navigate to the Security Hub service. In the left hand navigation area, click on Findings. You should see a row where the value of the Title column is \"ec2-force-vulnerabilities\", if not then in the Findings search box, type Title, under the pop-up Filters click on Title, then in the new popup, enter \"ec2-force-vulnerabilities\" then click Apply. Click the checkbox (left hand side) for the finding. In the upper right, click \"Actions\" then in the popup click on \"Ec2 DenySnapStop\" You should observe a green notification at top of page saying \"Successfully send findings to Amazon CloudwatchEvents\". I've submitted a request to include the action name in that message. Review the Cloudwatch log of the Lambda which got invoked. Log Group names are composed of the prefix \"/aws/lambda/custodian-\" followed by the policy name, so in this case \"aws/lambda/custodian-DenySnapStop\". Within that log group, open the most recent Log stream. Lines with \"ERROR\" indicate something is wrong, please let the event facilitor know if you see an ERROR. You should see at least a line containing \"invoking action:\" for each action in the policy. Optional: Review the complete payload of the Cloudwatch event which is logged directly after a line (usually line #2) ending with the text \"Processing event\". Optional, you can use the AWS Console and/or cli to confirm that the instance named \"RemediationTestTarget\" has really be stopped, snapshotted, and the IAM Instance Profile dissassociated. Now run the following command to reassociate the InstanceProfile as it's needed for the next module. aws ec2 associate - iam - instance - profile --iam-instance-profile Name=SecurityHubRemediationWorkshopCli --instance-id $(aws ec2 describe-instances --filters Name=tag:Name,Values=RemediationTestTarget --query Reservations[*].Instances[*].[InstanceId] --output text) Now run the following command to start the instance so the instance is ready for the next module. aws ec2 start - instances --instance-ids $(aws ec2 describe-instances --filters Name=tag:Name,Values=RemediationTestTarget Name=instance-state-name,Values=stopped --query Reservations[*].Instances[*].[InstanceId] --output text) If you get an error, the most likely reason is that the instance is still in the stopping state, wait 5-10 seconds then retry","title":"Module 3 - Security Hub Custom Actions - Human initiated automation"},{"location":"04-ec2-instance-high-risk-config/","text":"Module 4 - Automated Remediations - Vulnerability Event on EC2 Instance with a High Risk Configuration Run the following command, which invokes Cloud Custodian to run a policy named ec2-public-ingress-hubfinding which filters for a high risk configuation (Details TODO). ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module4/ec2-public-ingress-hubfinding.yml Run the following command to trigger an finding event in Security Hub on the with the resource being the RemediationTestTarget instance. ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module1/force-vulnerability-finding.yml Review the CloudWatch Log to observe that actions listed in the policy were invoked, and you can verify by using the console to view that the instance doesn't have an IAM Profile associated anymore and that a Snapshot was taken. Now run the following command to re-associate the InstanceProfile so the instance is ready for the next module. aws ec2 associate - iam - instance - profile --iam-instance-profile Name=SecurityHubRemediationWorkshopCli --instance-id $(aws ec2 describe-instances --filters \"Name=tag:Name,Values=RemediationTestTarget\" --query Reservations[*].Instances[*].[InstanceId] --output text) Review module4/ec2-public-ingress.yml observing that the lack of a \"mode\" section, compared to the policy deployed earlier in the module, means it can be run anytime from a CLI to find the risky configuration without requiring a vulnerability event.","title":"Module 4: Vulnerability Event on EC2 Instance with Very Risky Configuration"},{"location":"04-ec2-instance-high-risk-config/#module-4-automated-remediations-vulnerability-event-on-ec2-instance-with-a-high-risk-configuration","text":"Run the following command, which invokes Cloud Custodian to run a policy named ec2-public-ingress-hubfinding which filters for a high risk configuation (Details TODO). ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module4/ec2-public-ingress-hubfinding.yml Run the following command to trigger an finding event in Security Hub on the with the resource being the RemediationTestTarget instance. ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module1/force-vulnerability-finding.yml Review the CloudWatch Log to observe that actions listed in the policy were invoked, and you can verify by using the console to view that the instance doesn't have an IAM Profile associated anymore and that a Snapshot was taken. Now run the following command to re-associate the InstanceProfile so the instance is ready for the next module. aws ec2 associate - iam - instance - profile --iam-instance-profile Name=SecurityHubRemediationWorkshopCli --instance-id $(aws ec2 describe-instances --filters \"Name=tag:Name,Values=RemediationTestTarget\" --query Reservations[*].Instances[*].[InstanceId] --output text) Review module4/ec2-public-ingress.yml observing that the lack of a \"mode\" section, compared to the policy deployed earlier in the module, means it can be run anytime from a CLI to find the risky configuration without requiring a vulnerability event.","title":"Module 4 - Automated Remediations - Vulnerability Event on EC2 Instance with a High Risk Configuration"},{"location":"05-guardduty-iam-user/","text":"Module 5 - Automated Remediations - GuardDuty Event on IAMUser Run the following command: ${ CLOUDCUSTODIANDOCKERCMD } /home/custodian/securityhub-remediations/module5/iam-user-hubfinding-remediate-disable.yml Verify that the previous command resulted in output containing \"Provisioning policy lambda iam-user-hubfinding-remediate-disable\" Optional, but at least read: Next archive any existing sample GuardDuty Findings for the IAM User named GeneratedFindingUserName. While this is not nessesary when the create-sample-findings command (which is run later in this module) has never been run before, it won't harm anything to run. And if it's not run and the sample finding has already been generated, then the cloudwatch event needed for this module to function never gets triggered, so we're running it to eliminate sources of potential error. And if you want to rerun this module, you need to run this command. aws guardduty archive-findings \\ --detector-id \\ $(aws guardduty list-detectors --query DetectorIds --output text) \\ --finding-ids \\ $(aws guardduty list-findings \\ --detector-id \\ $(aws guardduty list-detectors --query DetectorIds --output text) \\ --finding-criteria '{\"Criterion\": {\"service.archived\": {\"Eq\":[\"false\"]},\"resource.accessKeyDetails.userName\": {\"Eq\":[\"GeneratedFindingUserName\"]}}}' --query 'FindingIds[0]' --output text) If you get an error like \"InternalServerErrorException\", the most likely explaination is that there are no findings currently, and if, you can move on the next step. 4. Archive any existing findings of this type in Security Hub, to be on the safe side. aws securityhub update-findings --record-state ARCHIVED --filters '{\"ResourceAwsIamAccessKeyUserName\":[{\"Value\": \"GeneratedFindingUserName\",\"Comparison\":\"EQUALS\"}]}' Run the following command to validate that the Access Keys status is currently active: aws iam list-access-keys --user-name GeneratedFindingUserName Run the following command, which creates a sample finding in GuardDuty, which automatically get imported into SecurityHub, which is an finding type 'UnauthorizedAccess:IAMUser/MaliciousIPCaller' on an IAMUser named GeneratedFindingUserName, which was created by cloudformation script in module 1. aws guardduty create-sample-findings --detector-id `aws guardduty list-detectors --query DetectorIds --output text` --finding-types 'UnauthorizedAccess:IAMUser/MaliciousIPCaller' First, validate that Guard Duty generated the sample finding by going to the Guard Duty Console and look for the finding type \"UnauthorizedAccess:IAMUser/MaliciousIPCaller\" Next, goto the Security Hub console and look the finding Title = \"API GeneratedFindingAPIName was invoked from a known malicious IP address\" however expect to need to wait for 2-5 minutes for it to appear. Next validate the execution of the automated remediation by looking within CloudWatch Logs, remember the LogGroup pattern of /aws/lambda/custodian-$(name of the cloud custodian policy). You are looking a lines containing \"policy:iam-user-hubfinding-remediate-disable invoking action:userremoveaccesskey resources:1\" followed by a line containing \"metric:ApiCalls Count:2 policy:iam-user-hubfinding-remediate-disable restype:iam-user\", if they don't appear will need to troubleshoot using the logs. Validate that the Access Keys were actually removed from the user by running the following command: aws iam list-access-keys --user-name GeneratedFindingUserName Evaluate the output by looking for \"Status\"=\"Inactive\"","title":"Module 5: GuardDuty Event on IAMUser"},{"location":"05-guardduty-iam-user/#module-5-automated-remediations-guardduty-event-on-iamuser","text":"Run the following command: ${ CLOUDCUSTODIANDOCKERCMD } /home/custodian/securityhub-remediations/module5/iam-user-hubfinding-remediate-disable.yml Verify that the previous command resulted in output containing \"Provisioning policy lambda iam-user-hubfinding-remediate-disable\" Optional, but at least read: Next archive any existing sample GuardDuty Findings for the IAM User named GeneratedFindingUserName. While this is not nessesary when the create-sample-findings command (which is run later in this module) has never been run before, it won't harm anything to run. And if it's not run and the sample finding has already been generated, then the cloudwatch event needed for this module to function never gets triggered, so we're running it to eliminate sources of potential error. And if you want to rerun this module, you need to run this command. aws guardduty archive-findings \\ --detector-id \\ $(aws guardduty list-detectors --query DetectorIds --output text) \\ --finding-ids \\ $(aws guardduty list-findings \\ --detector-id \\ $(aws guardduty list-detectors --query DetectorIds --output text) \\ --finding-criteria '{\"Criterion\": {\"service.archived\": {\"Eq\":[\"false\"]},\"resource.accessKeyDetails.userName\": {\"Eq\":[\"GeneratedFindingUserName\"]}}}' --query 'FindingIds[0]' --output text) If you get an error like \"InternalServerErrorException\", the most likely explaination is that there are no findings currently, and if, you can move on the next step. 4. Archive any existing findings of this type in Security Hub, to be on the safe side. aws securityhub update-findings --record-state ARCHIVED --filters '{\"ResourceAwsIamAccessKeyUserName\":[{\"Value\": \"GeneratedFindingUserName\",\"Comparison\":\"EQUALS\"}]}' Run the following command to validate that the Access Keys status is currently active: aws iam list-access-keys --user-name GeneratedFindingUserName Run the following command, which creates a sample finding in GuardDuty, which automatically get imported into SecurityHub, which is an finding type 'UnauthorizedAccess:IAMUser/MaliciousIPCaller' on an IAMUser named GeneratedFindingUserName, which was created by cloudformation script in module 1. aws guardduty create-sample-findings --detector-id `aws guardduty list-detectors --query DetectorIds --output text` --finding-types 'UnauthorizedAccess:IAMUser/MaliciousIPCaller' First, validate that Guard Duty generated the sample finding by going to the Guard Duty Console and look for the finding type \"UnauthorizedAccess:IAMUser/MaliciousIPCaller\" Next, goto the Security Hub console and look the finding Title = \"API GeneratedFindingAPIName was invoked from a known malicious IP address\" however expect to need to wait for 2-5 minutes for it to appear. Next validate the execution of the automated remediation by looking within CloudWatch Logs, remember the LogGroup pattern of /aws/lambda/custodian-$(name of the cloud custodian policy). You are looking a lines containing \"policy:iam-user-hubfinding-remediate-disable invoking action:userremoveaccesskey resources:1\" followed by a line containing \"metric:ApiCalls Count:2 policy:iam-user-hubfinding-remediate-disable restype:iam-user\", if they don't appear will need to troubleshoot using the logs. Validate that the Access Keys were actually removed from the user by running the following command: aws iam list-access-keys --user-name GeneratedFindingUserName Evaluate the output by looking for \"Status\"=\"Inactive\"","title":"Module 5 - Automated Remediations - GuardDuty Event on IAMUser"},{"location":"06-ebs-snapshot-public/","text":"Module 6 - Remediate an Public EBS-Snapshot This module will show how to setup an automated detection of a EBS Snaspshot that has been made public, with a finding submitted to Security Hub, then use Security Hub Custom action to delete the snapshot. Then we'll fully automate the remediation by changing the detection policy to perform the delete while still providing notification. Start by reviewing the file \"post-ebs-snapshot-public.yml\" using the Cloud9 IDE. Observe that the only action type is \"post-finding\". Also Observe that the following two lines instruct Cloud Custodian to deploy a CloudWatch rule which triggers on a regular schedule, configured to be every 5 minutes. type : periodic schedule : \"rate(5 minutes)\" Then deploy the automated detection policy by running the following command: ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module6/post-ebs-snapshot-public.yml Next we need to create a new EBS volume, however no data will be stored in it, it will not be attached anywhere. Note how the VolumeId is saved for the next step. export WorkshopVolumeId=$(aws ec2 create-volume --availability-zone $(aws ec2 describe-availability-zones --query AvailabilityZones[0].ZoneName --output text) --size 1 --query VolumeId --output text) Then we Snapshot the volume just created, also saving the SnapshotId for a future step. export WorkshopSnapshotId=$(aws ec2 create-snapshot --volume-id $WorkshopVolumeId --query SnapshotId --output text) This step makes the snapshot public. aws ec2 modify-snapshot-attribute --snapshot-id $WorkshopSnapshotId --attribute createVolumePermission --operation-type add --group-names all Now navigate to the Findings part of Security Hub's console. Look for a finding who's title is the same as the policy name from step 1 then click it's checkbox. If you don't see it, you may need to wait up to 5 minutes (remember the schedule based CloudWatch Rule from Step 1) for it to appear after refreshing the browser. Click the dropdown for Actions then select \"Ebs-Snapshot Delete\" (This custom action is one of the ones deployed in Module 2). Confirm the snapshot got deleted by running: aws ec2 describe-snapshots --snapshot-ids $WorkshopSnapshotId then confirming the response is similar to: An error occurred (InvalidSnapshot.NotFound) when calling the DescribeSnapshots operation: The snapshot 'snap-0643b6dcd0a6f01f0' does not exist. Now edit the file \"post-ebs-snapshot-public.yml\" by adding an action to delete the snapshot at time of initial detection, which transform the policy from a detective control to a remediation control. Append the following line to the file, where the dash should be in column 5. - type: delete Save the file in the IDE. Run the following command which redeploys the policy: ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module6/post-ebs-snapshot-public.yml Run the following three commands: export WorkshopSnapshotId=$(aws ec2 create-snapshot --volume-id $WorkshopVolumeId --query SnapshotId --output text) aws ec2 modify-snapshot-attribute --snapshot-id $WorkshopSnapshotId --attribute createVolumePermission --operation-type add --group-names all aws ec2 describe-snapshots --snapshot-ids $WorkshopSnapshotId Repeat running the last command, the describe-snapshots one, until either the InvalidSnapshot.NotFound error is received (which means success, move on the the next step) or if after 5 minutes it still has not been deleted, the most likely cause is Step 9 did not get done correctly, review the CloudWatch logs for the policy, or the file did not get saved (view the file from the terminal to see if it has the type: delete line), or the policy did not get redeployed in step 11. The remainder of this module shows you how to customize the automated remediation by adding an exception filter then provides information on more advanced filters. If you have a use case for publicly sharing a snapshot, a change to the policy could be made to filter for only those snapshots which do not have a specific value for a specific tag. In this example we use the Tag key of \"PublicIntent\" and Tag value of \"True\". Start by updating the filter section of the policy by inserting the following lines at line 13 or 16, as long as it's within the filter section and doesn't overlap the existing filter, with the dash character at column 13. The way to read the filter match the condition of not-equal when testing for Tag key of value. Thus resources which have this tag value will get filtered out aka excluded, thus the actions will not get invoked on those filtered out resources. - type: value op: not-equal key: \"tag:PublicIntent\" value: \"True\" Save the file. Deploy the updated policy ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module6/post-ebs-snapshot-public.yml Run the following command noticing that this time it's created with a Tag key and value which matches the filter specified. export WorkshopSnapshotId=$(aws ec2 create-snapshot --volume-id $WorkshopVolumeId --query SnapshotId --output text --tag-specifications 'ResourceType=snapshot,Tags=[{Key=PublicIntent,Value=True}]') Run the following to make the snapshot public: aws ec2 modify-snapshot-attribute --snapshot-id $WorkshopSnapshotId --attribute createVolumePermission --operation-type add --group-names all Run the following which waits for 5 minutes to then show the snapshot did not get deleted, a result of the exception filter. sleep 300 ; aws ec2 describe-snapshots --snapshot-ids $WorkshopSnapshotId For good hygene, delete the public snapshot manually. aws ec2 delete-snapshots --snapshot-ids $WorkshopSnapshotId To learn more about the types of filters that can be added to any Cloud Custodian Policy, click generic filters . To learn about the filters that can be applied to EBS Snapshots, run the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.filters To learn more about the attributes of a specific filter, append the filters name to the command, like the following example for the skip-ami-snapshots filter docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.filters.skip-ami-snapshots To learn about what AWS resource types are supported by Cloud Custodian, run the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema aws The actions supported by a specific resource can be viewed by using the schema command with the parameter of .actions, like in the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.actions And just like filters, the attributes for a given action can be viewed by running the schema command specifing the .actions. , like the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.actions.post-finding","title":"Module 6: Remediate an Public EBS-Snapshot"},{"location":"06-ebs-snapshot-public/#module-6-remediate-an-public-ebs-snapshot","text":"This module will show how to setup an automated detection of a EBS Snaspshot that has been made public, with a finding submitted to Security Hub, then use Security Hub Custom action to delete the snapshot. Then we'll fully automate the remediation by changing the detection policy to perform the delete while still providing notification. Start by reviewing the file \"post-ebs-snapshot-public.yml\" using the Cloud9 IDE. Observe that the only action type is \"post-finding\". Also Observe that the following two lines instruct Cloud Custodian to deploy a CloudWatch rule which triggers on a regular schedule, configured to be every 5 minutes. type : periodic schedule : \"rate(5 minutes)\" Then deploy the automated detection policy by running the following command: ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module6/post-ebs-snapshot-public.yml Next we need to create a new EBS volume, however no data will be stored in it, it will not be attached anywhere. Note how the VolumeId is saved for the next step. export WorkshopVolumeId=$(aws ec2 create-volume --availability-zone $(aws ec2 describe-availability-zones --query AvailabilityZones[0].ZoneName --output text) --size 1 --query VolumeId --output text) Then we Snapshot the volume just created, also saving the SnapshotId for a future step. export WorkshopSnapshotId=$(aws ec2 create-snapshot --volume-id $WorkshopVolumeId --query SnapshotId --output text) This step makes the snapshot public. aws ec2 modify-snapshot-attribute --snapshot-id $WorkshopSnapshotId --attribute createVolumePermission --operation-type add --group-names all Now navigate to the Findings part of Security Hub's console. Look for a finding who's title is the same as the policy name from step 1 then click it's checkbox. If you don't see it, you may need to wait up to 5 minutes (remember the schedule based CloudWatch Rule from Step 1) for it to appear after refreshing the browser. Click the dropdown for Actions then select \"Ebs-Snapshot Delete\" (This custom action is one of the ones deployed in Module 2). Confirm the snapshot got deleted by running: aws ec2 describe-snapshots --snapshot-ids $WorkshopSnapshotId then confirming the response is similar to: An error occurred (InvalidSnapshot.NotFound) when calling the DescribeSnapshots operation: The snapshot 'snap-0643b6dcd0a6f01f0' does not exist. Now edit the file \"post-ebs-snapshot-public.yml\" by adding an action to delete the snapshot at time of initial detection, which transform the policy from a detective control to a remediation control. Append the following line to the file, where the dash should be in column 5. - type: delete Save the file in the IDE. Run the following command which redeploys the policy: ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module6/post-ebs-snapshot-public.yml Run the following three commands: export WorkshopSnapshotId=$(aws ec2 create-snapshot --volume-id $WorkshopVolumeId --query SnapshotId --output text) aws ec2 modify-snapshot-attribute --snapshot-id $WorkshopSnapshotId --attribute createVolumePermission --operation-type add --group-names all aws ec2 describe-snapshots --snapshot-ids $WorkshopSnapshotId Repeat running the last command, the describe-snapshots one, until either the InvalidSnapshot.NotFound error is received (which means success, move on the the next step) or if after 5 minutes it still has not been deleted, the most likely cause is Step 9 did not get done correctly, review the CloudWatch logs for the policy, or the file did not get saved (view the file from the terminal to see if it has the type: delete line), or the policy did not get redeployed in step 11. The remainder of this module shows you how to customize the automated remediation by adding an exception filter then provides information on more advanced filters. If you have a use case for publicly sharing a snapshot, a change to the policy could be made to filter for only those snapshots which do not have a specific value for a specific tag. In this example we use the Tag key of \"PublicIntent\" and Tag value of \"True\". Start by updating the filter section of the policy by inserting the following lines at line 13 or 16, as long as it's within the filter section and doesn't overlap the existing filter, with the dash character at column 13. The way to read the filter match the condition of not-equal when testing for Tag key of value. Thus resources which have this tag value will get filtered out aka excluded, thus the actions will not get invoked on those filtered out resources. - type: value op: not-equal key: \"tag:PublicIntent\" value: \"True\" Save the file. Deploy the updated policy ${ CLOUDCUSTODIANDOCKERCMD } securityhub-remediations/module6/post-ebs-snapshot-public.yml Run the following command noticing that this time it's created with a Tag key and value which matches the filter specified. export WorkshopSnapshotId=$(aws ec2 create-snapshot --volume-id $WorkshopVolumeId --query SnapshotId --output text --tag-specifications 'ResourceType=snapshot,Tags=[{Key=PublicIntent,Value=True}]') Run the following to make the snapshot public: aws ec2 modify-snapshot-attribute --snapshot-id $WorkshopSnapshotId --attribute createVolumePermission --operation-type add --group-names all Run the following which waits for 5 minutes to then show the snapshot did not get deleted, a result of the exception filter. sleep 300 ; aws ec2 describe-snapshots --snapshot-ids $WorkshopSnapshotId For good hygene, delete the public snapshot manually. aws ec2 delete-snapshots --snapshot-ids $WorkshopSnapshotId To learn more about the types of filters that can be added to any Cloud Custodian Policy, click generic filters . To learn about the filters that can be applied to EBS Snapshots, run the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.filters To learn more about the attributes of a specific filter, append the filters name to the command, like the following example for the skip-ami-snapshots filter docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.filters.skip-ami-snapshots To learn about what AWS resource types are supported by Cloud Custodian, run the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema aws The actions supported by a specific resource can be viewed by using the schema command with the parameter of .actions, like in the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.actions And just like filters, the attributes for a given action can be viewed by running the schema command specifing the .actions. , like the following: docker run -it --rm ${ SECHUBWORKSHOP_CONTAINER } schema ebs-snapshot.actions.post-finding","title":"Module 6 - Remediate an Public EBS-Snapshot"},{"location":"07-cleanup/","text":"Module 7 - Cleanup If you conducted this workshop with an account provided by an AWS Event, then cleanup will be handled for you by the presentor, thus there is no remaining action expected of you other than completing the workshop evaluation. However, if you used your own account, then follow these steps to cleanup your account. Delete the Cloudwatch Event rules and lambdas deployed by Cloud Custodian by running the following command from the Cloud9 IDE's terminal prompt wget https://raw.githubusercontent.com/cloud-custodian/cloud-custodian/master/tools/ops/mugc.py docker run -it --rm --cap-drop ALL -v /home/ec2-user/environment/securityhub-remediations:/home/custodian/securityhub-remediations:ro -v /home/ec2-user/.aws:/home/custodian/.aws:ro --entrypoint /usr/local/bin/python ${ SECHUBWORKSHOP_CONTAINER } securityhub-remediations/mugc.py --present -c securityhub-remediations/module3/ec2-sechub-custom-actions.yml Run the following commands. If you get errors, then it could be that cleanup of custom actions was added to the mugc.py ACCOUNTID=$(aws sts get-caller-identity --query Account --output text) aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/DenySnapStop aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/DisableKey aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/PostOpsItem aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/RemPA aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/Delete Delete the CloudFormation stack created in module 1 ( SecurityHubRemediations ) Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . While we strongly recommend you leave GuardDuty enabled, however if you really want to disable it, perform the following: Go to the Amazon GuardDuty console. Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. While we strongly recommend you leave Security Hub enabled, however if you really want to disable it, perform the following: Go to the AWS Security Hub console. Click on Settings on the left navigation. Click the General on the top navigation. Click Disable AWS Security Hub .","title":"Module 7: Cleanup of resources"},{"location":"07-cleanup/#module-7-cleanup","text":"If you conducted this workshop with an account provided by an AWS Event, then cleanup will be handled for you by the presentor, thus there is no remaining action expected of you other than completing the workshop evaluation. However, if you used your own account, then follow these steps to cleanup your account. Delete the Cloudwatch Event rules and lambdas deployed by Cloud Custodian by running the following command from the Cloud9 IDE's terminal prompt wget https://raw.githubusercontent.com/cloud-custodian/cloud-custodian/master/tools/ops/mugc.py docker run -it --rm --cap-drop ALL -v /home/ec2-user/environment/securityhub-remediations:/home/custodian/securityhub-remediations:ro -v /home/ec2-user/.aws:/home/custodian/.aws:ro --entrypoint /usr/local/bin/python ${ SECHUBWORKSHOP_CONTAINER } securityhub-remediations/mugc.py --present -c securityhub-remediations/module3/ec2-sechub-custom-actions.yml Run the following commands. If you get errors, then it could be that cleanup of custom actions was added to the mugc.py ACCOUNTID=$(aws sts get-caller-identity --query Account --output text) aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/DenySnapStop aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/DisableKey aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/PostOpsItem aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/RemPA aws securityhub delete-action-target --action-target-arn arn:aws:securityhub: ${ AWS_DEFAULT_REGION } : ${ ACCOUNTID } :action/custom/Delete Delete the CloudFormation stack created in module 1 ( SecurityHubRemediations ) Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . While we strongly recommend you leave GuardDuty enabled, however if you really want to disable it, perform the following: Go to the Amazon GuardDuty console. Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. While we strongly recommend you leave Security Hub enabled, however if you really want to disable it, perform the following: Go to the AWS Security Hub console. Click on Settings on the left navigation. Click the General on the top navigation. Click Disable AWS Security Hub .","title":"Module 7 - Cleanup"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"}]}